{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = tf.random.uniform([1], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5403172], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[0.84979901, 0.65417176],\n",
       "       [0.18178625, 0.57026643]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand2 = tf.random.uniform([2, 2], 0, 1, dtype=tf.dtypes.float64)\n",
    "rand2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand2.shape\n",
    "rand2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.6870353 , 0.98615944, 0.5070567 , 0.7898574 ], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand3= tf.random.uniform([4], 0, 1)\n",
    "rand3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **뉴런만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5462379640437204\n",
      "99 -0.1053841630652207 0.1053841630652207\n",
      "199 -0.05323732301567157 0.05323732301567157\n",
      "299 -0.035244521155925856 0.035244521155925856\n",
      "399 -0.026257543989735555 0.026257543989735555\n",
      "499 -0.02089353443274511 0.02089353443274511\n",
      "599 -0.01733681577213171 0.01733681577213171\n",
      "699 -0.014808569586266994 0.014808569586266994\n",
      "799 -0.012920400062973075 0.012920400062973075\n",
      "899 -0.011457206738145776 0.011457206738145776\n",
      "999 -0.010290369727732538 0.010290369727732538\n"
     ]
    }
   ],
   "source": [
    "#[1] 활성화함수 만들기: sigmoid\n",
    "#활성화함수: sigmoid, reLU\n",
    "\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "#[2] 뉴런의 입력과 출력 정의하기\n",
    "#입력이 1일 때 기대출력이 0이 되는 뉴런: \n",
    "x = 1\n",
    "y = 0\n",
    "\n",
    "w = tf.random.normal([1], 0, 1)      #<------ 뉴런! \n",
    "output = sigmoid(x * w)\n",
    "\n",
    "print(output)\n",
    "\n",
    "#error 구하기\n",
    "y_error = y - output\n",
    "\n",
    "#[3]내가 원하는 값(y)이 나오도록 뉴런(가중치) 조절하기: 경사하강법(Gradient Descent)\n",
    "#경사하강법: 가중치(w)에 (입력 * 학습률 * 에러)를 더해주는 것 \n",
    "#  --손실곡선의 기울기. 손실곡선을 미분한 다음 그 값을 이용해서 가중치가 손실이 가장 낮아지는 지점에 도달하도록 반복 계산\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x * w)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error     #학습률: 0.1\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(i, error, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.5 0.5\n",
      "199 0.5 0.5\n",
      "299 0.5 0.5\n",
      "399 0.5 0.5\n",
      "499 0.5 0.5\n",
      "599 0.5 0.5\n",
      "699 0.5 0.5\n",
      "799 0.5 0.5\n",
      "899 0.5 0.5\n",
      "999 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "#입력이 0일 때 기대출력이 1이 되는 뉴런:\n",
    "x = 0\n",
    "y = 1\n",
    "w = tf.random.normal([1], 0, 1)\n",
    "\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x * w)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(i, error, output)\n",
    "        \n",
    "#[!] 결과값이 같다: 0을 곱하기 때문에 w가 변하지 않는다. \n",
    "# =한 값만 나온다.\n",
    "# =편향된 값만 나온다. \n",
    "#-----> 편향된 값만 나오는 것을 방지하기 위해 '편향(bias)'를 뉴런에 적용시킨다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.1295308928328771 0.8704691071671229\n",
      "199 0.059177442002129155 0.9408225579978708\n",
      "299 0.03780679123414521 0.9621932087658548\n",
      "399 0.027667723528267518 0.9723322764717325\n",
      "499 0.02178176061065329 0.9782182393893467\n",
      "599 0.017946214377701164 0.9820537856222988\n",
      "699 0.015252101926194528 0.9847478980738055\n",
      "799 0.013257390809347291 0.9867426091906527\n",
      "899 0.011721781521260133 0.9882782184787399\n",
      "999 0.010503562474805106 0.9894964375251949\n"
     ]
    }
   ],
   "source": [
    "#입력이 0일 때 기대출력이 1이 되는 뉴런의 학습에 편향 더하기:\n",
    "x = 0\n",
    "y = 1\n",
    "w = tf.random.normal([1], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)    #편향으로는 보편적으로 1을 사용한다. \n",
    "\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x * w + 1 * b)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error\n",
    "    b = b + 1 * 0.1 * error\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(i, error, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **첫 번째 신경망 네트워크: AND**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True는 1 False는 0 을 사용하자\n",
      "199 -0.10434909629443777\n",
      "399 -0.06355481496649387\n",
      "599 -0.04556591767454216\n",
      "799 -0.03541460460420335\n",
      "999 -0.028911235059643017\n",
      "1199 -0.02439870172777982\n",
      "1399 -0.021089357358266007\n",
      "1599 -0.018560686806585017\n",
      "1799 -0.01656779971433496\n",
      "1999 -0.0149566323648318\n",
      "X: [1 1] Y: [1] Output: 0.9650829129810596\n",
      "X: [1 0] Y: [0] Output: 0.024744883077498017\n",
      "X: [0 1] Y: [0] Output: 0.024820194807318507\n",
      "X: [0 0] Y: [0] Output: 2.3364187346359582e-05\n"
     ]
    }
   ],
   "source": [
    "#두 개의 입력을 받는 AND 연산 \n",
    "#입력값 두개가 모두 참일때만 참 반환\n",
    "\n",
    "#cf. True, False로 어떤 수를 사용해야할까? (딥러닝의 주요 입력값은 int 또는 float!)\n",
    "print('True는', int(True),\n",
    "     'False는', int(False),\n",
    "     '을 사용하자')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[1], [0], [0], [0]])\n",
    "\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j] * w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)\n",
    "        \n",
    "#AND 네트워크 평가하기\n",
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **두 번째 신경망 네트워크: OR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 -0.04850842646722983\n",
      "399 -0.025606662774803696\n",
      "599 -0.017274601459725758\n",
      "799 -0.012987975456363154\n",
      "999 -0.010386948371658253\n",
      "1199 -0.008645036212111247\n",
      "1399 -0.007398823541600298\n",
      "1599 -0.006463543131123399\n",
      "1799 -0.0057370321790597804\n",
      "1999 -0.005154939492648614\n",
      "X: [1 1] Y: [1] Output: 0.9999971968883226\n",
      "X: [1 0] Y: [1] Output: 0.989779481259482\n",
      "X: [0 1] Y: [1] Output: 0.9897561660934151\n",
      "X: [0 0] Y: [0] Output: 0.025558117303969473\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[1], [1], [1], [0]])\n",
    "\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j] * w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)\n",
    "        \n",
    "#OR 네트워크 평가하기\n",
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **세 번째 신경망 네트워크: XOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 0.005018549744792322\n",
      "399 0.0002040018254592102\n",
      "599 8.280544573691095e-06\n",
      "799 3.5180860535888314e-07\n",
      "999 2.7921316370083105e-09\n",
      "1199 1.8614210173240053e-09\n",
      "1399 1.8614210173240053e-09\n",
      "1599 1.8614210173240053e-09\n",
      "1799 1.8614210173240053e-09\n",
      "1999 1.8614210173240053e-09\n",
      "X: [1 1] Y: [0] Output: 0.5128176323940516\n",
      "X: [1 0] Y: [1] Output: 0.5128176314633411\n",
      "X: [0 1] Y: [1] Output: 0.4999999990686774\n",
      "X: [0 0] Y: [0] Output: 0.49999999813735485\n",
      "w: tf.Tensor([5.1281769e-02 3.7252903e-09], shape=(2,), dtype=float32)\n",
      "b: tf.Tensor([-7.450581e-09], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#XOR: 홀수개의 입력이 참일때만 결괏값이 참이된다\n",
    "#입력값이 2개일 떄: 2개의 입력값이 다를 때 참이된다. \n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j] * w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)\n",
    "        \n",
    "#XOR 네트워크 평가하기\n",
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))\n",
    "    \n",
    "#[!]에러값이 변하다가 '어느 시점'부터 변하지 않는다: \n",
    "#output을 구성하는 w와 b 출력해보기: \n",
    "print('w:', w)    #----> 첫번째 입력이 두번째 입력보다 큰 영향\n",
    "print('b:', b)    #----> 두번째 입력과 비슷하게 거의 영향이 없다\n",
    "#네트워크가 어떤 일을 하려는지 불명확함. ==>여러 개의 퍼셉트론을 사용하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#tf.keras를 이용한 XOR 네트워크 계산하기\n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units = 2, activation = 'sigmoid', input_shape = (2, )),\n",
    "    tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "])\n",
    "#model: 딥러닝 계산을 위한 여러 함수와 변수의 묶음딥러닝을 계산하는 가장 핵심적인 단위\n",
    "\n",
    "#tf.keras.Sequential: \n",
    "#model에서 가장 많이 쓰이는 구조. \n",
    "#순차적으로 뉴런과 뉴런이 합쳐진 단위(레이어)를 일직선으로 배치하는 것.\n",
    "#=시퀀셜 네트웤, 시퀀셜 모델\n",
    "#인수: 레이어가 차례대로 정의된 리스트 전달\n",
    "\n",
    "#tf.keras.layers.Dense: \n",
    "#레이어 정의 명령어. Dense는 가장 기본적인 레이어. \n",
    "#레이어 입출력 사이에 있는 모든 뉴런이 서로 연결되는 레이어. \n",
    "\n",
    "#units: 레이어를 구성하는 뉴런 수. cf.뉴런이 많을수록 레이어 성능 좋아지지만 메모리 UP\n",
    "\n",
    "#input_shape: 시퀀셜모델의 첫번쩨 레이어에서만 정의.입력의 차원 수가 어떻게 되는지 정의.\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(lr = 0.1), loss = 'mse')\n",
    "#optimizer: 최적화함수. 딥러닝의 학습식 정의.\n",
    "\n",
    "#SGD: 경사하강법(Stochastic Gradient Descent)\n",
    "#=>가중치를 업데이트할 때 미분을 통해 기울기를 구한 다음 기울기가 낮은 쪽으로 업데이트하겠다! \n",
    "#'stochastic': 전체를 한번에 계산하지 않고 확률적으로 일ㄹ부 샘플을 구해서 조금씩 나눠 계산하겠다!\n",
    "\n",
    "#loss: error와 비슷한 개념. 손실을 줄이는 방향으로 학습. \n",
    "\n",
    "#mse: 평균제곱오차(Mean Squared Error)\n",
    "#기대출력에서 실제 출력을 뺀 뒤 제곱한 값을 평균\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
