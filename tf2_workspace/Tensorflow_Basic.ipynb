{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = tf.random.uniform([1], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.23172212], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[0.16683761, 0.69907497],\n",
       "       [0.47256245, 0.1545962 ]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand2 = tf.random.uniform([2, 2], 0, 1, dtype=tf.dtypes.float64)\n",
    "rand2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand2.shape\n",
    "rand2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.46521723, 0.7441504 , 0.1558994 , 0.72263217], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand3= tf.random.uniform([4], 0, 1)\n",
    "rand3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **뉴런만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23857340368707922\n",
      "99 -0.0778996460149631 0.0778996460149631\n",
      "199 -0.0448869333993842 0.0448869333993842\n",
      "299 -0.03132597136031582 0.03132597136031582\n",
      "399 -0.02400272419246518 0.02400272419246518\n",
      "499 -0.01943381797758382 0.01943381797758382\n",
      "599 -0.016316546571690724 0.016316546571690724\n",
      "699 -0.014056085032462926 0.014056085032462926\n",
      "799 -0.012342882234992504 0.012342882234992504\n",
      "899 -0.011000194241897012 0.011000194241897012\n",
      "999 -0.009919826386252995 0.009919826386252995\n"
     ]
    }
   ],
   "source": [
    "#[1] 활성화함수 만들기: sigmoid\n",
    "#활성화함수: sigmoid, reLU\n",
    "\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "#[2] 뉴런의 입력과 출력 정의하기\n",
    "#입력이 1일 때 기대출력이 0이 되는 뉴런: \n",
    "x = 1\n",
    "y = 0\n",
    "\n",
    "w = tf.random.normal([1], 0, 1)      #<------ 뉴런! \n",
    "output = sigmoid(x * w)\n",
    "\n",
    "print(output)\n",
    "\n",
    "#error 구하기\n",
    "y_error = y - output\n",
    "\n",
    "#[3]내가 원하는 값(y)이 나오도록 뉴런(가중치) 조절하기: 경사하강법(Gradient Descent)\n",
    "#경사하강법: 가중치(w)에 (입력 * 학습률 * 에러)를 더해주는 것 \n",
    "#  --손실곡선의 기울기. 손실곡선을 미분한 다음 그 값을 이용해서 가중치가 손실이 가장 낮아지는 지점에 도달하도록 반복 계산\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x * w)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error     #학습률: 0.1\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(i, error, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.5 0.5\n",
      "199 0.5 0.5\n",
      "299 0.5 0.5\n",
      "399 0.5 0.5\n",
      "499 0.5 0.5\n",
      "599 0.5 0.5\n",
      "699 0.5 0.5\n",
      "799 0.5 0.5\n",
      "899 0.5 0.5\n",
      "999 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "#입력이 0일 때 기대출력이 1이 되는 뉴런:\n",
    "x = 0\n",
    "y = 1\n",
    "w = tf.random.normal([1], 0, 1)\n",
    "\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x * w)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(i, error, output)\n",
    "        \n",
    "#[!] 결과값이 같다: 0을 곱하기 때문에 w가 변하지 않는다. \n",
    "# =한 값만 나온다.\n",
    "# =편향된 값만 나온다. \n",
    "#-----> 편향된 값만 나오는 것을 방지하기 위해 '편향(bias)'를 뉴런에 적용시킨다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.06817694475140834 0.9318230552485917\n",
      "199 0.041382013786833594 0.9586179862131664\n",
      "299 0.02955681863596271 0.9704431813640373\n",
      "399 0.022943300087966523 0.9770566999120335\n",
      "499 0.018730556031242518 0.9812694439687575\n",
      "599 0.015816483631189593 0.9841835163688104\n",
      "699 0.013682622608932493 0.9863173773910675\n",
      "799 0.012053529668816676 0.9879464703311833\n",
      "899 0.010769474503053544 0.9892305254969465\n",
      "999 0.009731609195697044 0.990268390804303\n"
     ]
    }
   ],
   "source": [
    "#입력이 0일 때 기대출력이 1이 되는 뉴런의 학습에 편향 더하기:\n",
    "x = 0\n",
    "y = 1\n",
    "w = tf.random.normal([1], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)    #편향으로는 보편적으로 1을 사용한다. \n",
    "\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x * w + 1 * b)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error\n",
    "    b = b + 1 * 0.1 * error\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(i, error, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **첫 번째 신경망 네트워크: AND**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True는 1 False는 0 을 사용하자\n",
      "199 -0.1102554052535689\n",
      "399 -0.06568725104315914\n",
      "599 -0.04666688750070012\n",
      "799 -0.036083767961627336\n",
      "999 -0.029359903225083465\n",
      "1199 -0.024719127242795937\n",
      "1399 -0.021329000110601994\n",
      "1599 -0.01874759790299529\n",
      "1799 -0.016716244513070633\n",
      "1999 -0.015077526523052213\n",
      "X: [1 1] Y: [1] Output: 0.9647990349990229\n",
      "X: [1 0] Y: [0] Output: 0.024944115643210082\n",
      "X: [0 1] Y: [0] Output: 0.025020588159518495\n",
      "X: [0 0] Y: [0] Output: 2.3952341757238866e-05\n"
     ]
    }
   ],
   "source": [
    "#두 개의 입력을 받는 AND 연산 \n",
    "#입력값 두개가 모두 참일때만 참 반환\n",
    "\n",
    "#cf. True, False로 어떤 수를 사용해야할까? (딥러닝의 주요 입력값은 int 또는 float!)\n",
    "print('True는', int(True),\n",
    "     'False는', int(False),\n",
    "     '을 사용하자')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[1], [0], [0], [0]])\n",
    "\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j] * w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)\n",
    "        \n",
    "#AND 네트워크 평가하기\n",
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **두 번째 신경망 네트워크: OR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 -0.04850842646722983\n",
      "399 -0.025606662774803696\n",
      "599 -0.017274601459725758\n",
      "799 -0.012987975456363154\n",
      "999 -0.010386948371658253\n",
      "1199 -0.008645036212111247\n",
      "1399 -0.007398823541600298\n",
      "1599 -0.006463543131123399\n",
      "1799 -0.0057370321790597804\n",
      "1999 -0.005154939492648614\n",
      "X: [1 1] Y: [1] Output: 0.9999971968883226\n",
      "X: [1 0] Y: [1] Output: 0.989779481259482\n",
      "X: [0 1] Y: [1] Output: 0.9897561660934151\n",
      "X: [0 0] Y: [0] Output: 0.025558117303969473\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[1], [1], [1], [0]])\n",
    "\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j] * w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)\n",
    "        \n",
    "#OR 네트워크 평가하기\n",
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **세 번째 신경망 네트워크: XOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 -0.009316108401358991\n",
      "399 -0.0003789442627146755\n",
      "599 -1.539763067615052e-05\n",
      "799 -6.319523835340846e-07\n",
      "999 1.1102230246251565e-16\n",
      "1199 3.722842145670313e-09\n",
      "1399 3.722842145670313e-09\n",
      "1599 3.722842145670313e-09\n",
      "1799 3.722842145670313e-09\n",
      "1999 3.722842145670313e-09\n",
      "X: [1 1] Y: [0] Output: 0.5128176286712095\n",
      "X: [1 0] Y: [1] Output: 0.5128176305326305\n",
      "X: [0 1] Y: [1] Output: 0.4999999990686774\n",
      "X: [0 0] Y: [0] Output: 0.5000000009313226\n",
      "w: tf.Tensor([ 5.1281754e-02 -7.4505806e-09], shape=(2,), dtype=float32)\n",
      "b: tf.Tensor([3.7252903e-09], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#XOR: 홀수개의 입력이 참일때만 결괏값이 참이된다\n",
    "#입력값이 2개일 떄: 2개의 입력값이 다를 때 참이된다. \n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j] * w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)\n",
    "        \n",
    "#XOR 네트워크 평가하기\n",
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))\n",
    "    \n",
    "#[!]에러값이 변하다가 '어느 시점'부터 변하지 않는다: \n",
    "#output을 구성하는 w와 b 출력해보기: \n",
    "print('w:', w)    #----> 첫번째 입력이 두번째 입력보다 큰 영향\n",
    "print('b:', b)    #----> 두번째 입력과 비슷하게 거의 영향이 없다\n",
    "#네트워크가 어떤 일을 하려는지 불명확함. ==>여러 개의 퍼셉트론을 사용하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#tf.keras를 이용한 XOR 네트워크 계산하기\n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units = 2, activation = 'sigmoid', input_shape = (2, )),\n",
    "    tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(lr = 0.1), loss = 'mse')\n",
    "#model: 딥러닝 계산을 위한 여러 함수와 변수의 묶음딥러닝을 계산하는 가장 핵심적인 단위\n",
    "#tf.keras.Sequential: model에서 가장 많이 쓰이는 구조. \n",
    "#                     순차적으로 뉴런과 뉴런이 합쳐진 단위(레이어)를 일직선으로 배치하는 것.\n",
    "#                     =시퀀셜 네트웤, 시퀀셜 모델\n",
    "#                     인수: 레이어가 차례대로 정의된 리스트 전달\n",
    "#tf.keras.layers.Dense: 레이어 정의 명령어. Dense는 가장 기본적인 레이어. \n",
    "#                       레이어 입출력 사이에 있는 모든 뉴런이 서로 연결되는 레이어. \n",
    "#                       units: 레이어를 구성하는 뉴런 수. cf.뉴런이 많을수록 레이어 성능 좋아지지만 메모리 UP\n",
    "#                       input_shape: 시퀀셜모델의 첫번쩨 레이어에서만 정의.입력의 차원 수가 어떻게 되는지 정의.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
